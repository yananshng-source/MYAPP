# app.py
import streamlit as st
import os
import pandas as pd
from io import BytesIO
from PIL import Image, ImageOps, ImageEnhance
import requests
from urllib.parse import urljoin
from bs4 import BeautifulSoup
import re
from datetime import datetime

st.set_page_config(page_title="ç»¼åˆå¤„ç†å·¥å…·ç®±", layout="wide")
st.title("ğŸ§° ç»¼åˆå¤„ç†å·¥å…·ç®± - Tabç‰ˆ")

# ------------------------ Tabs ------------------------
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ç½‘é¡µè¡¨æ ¼æŠ“å–",
    "ç½‘é¡µå›¾ç‰‡ä¸‹è½½",
    "å›¾ç‰‡è£å‰ª",
    "é«˜æ ¡é€‰ç§‘è½¬æ¢",
    "Excelæ—¥æœŸå¤„ç†"
])


# ------------------------ åŠŸèƒ½å‡½æ•° ------------------------
def scrape_table(url_list, group_cols):
    group_list = [g.strip() for g in group_cols.split(",") if g.strip()]
    sheet_data = {}
    all_data = []

    for idx, url in enumerate(url_list, start=1):
        try:
            r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
            r.raise_for_status()
            dfs = pd.read_html(r.text)
            for i, df in enumerate(dfs):
                name = f"ç½‘é¡µ{idx}_è¡¨{i + 1}"
                sheet_data[name] = df
                all_data.append(df)
        except:
            continue

    if sheet_data:
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            for name, df in sheet_data.items():
                df.to_excel(writer, sheet_name=name[:31], index=False)
            if all_data:
                pd.concat(all_data, ignore_index=True).to_excel(writer, sheet_name="æ±‡æ€»", index=False)
        output.seek(0)
        return output
    return None


def download_images_from_urls(url_list, output_dir=None):
    if output_dir is None:
        output_dir = os.path.join(os.path.expanduser("~"), "Desktop", "downloaded_images")
    os.makedirs(output_dir, exist_ok=True)
    session = requests.Session()
    session.headers.update({"User-Agent": "Mozilla/5.0"})
    downloaded_files = []

    for idx, url in enumerate(url_list, start=1):
        try:
            r = session.get(url, timeout=10)
            r.raise_for_status()
            soup = BeautifulSoup(r.content, "html.parser")
            title_tag = soup.find("title")
            title = title_tag.string.strip() if title_tag else f"ç½‘é¡µ{idx}"
            safe_title = "".join([c if c not in r'\/:*?"<>|' else "_" for c in title])
            imgs = soup.find_all("img")
            for i, img_tag in enumerate(imgs, start=1):
                src = img_tag.get("src") or img_tag.get("data-src")
                if not src:
                    continue
                full_url = urljoin(url, src.strip())
                try:
                    resp_img = session.get(full_url, timeout=10)
                    resp_img.raise_for_status()
                    ext = os.path.splitext(full_url)[1] or ".jpg"
                    fname = f"{safe_title}_{i}{ext}"
                    fpath = os.path.join(output_dir, fname)
                    with open(fpath, "wb") as f:
                        f.write(resp_img.content)
                    downloaded_files.append(fpath)
                except:
                    continue
        except:
            continue
    return output_dir, downloaded_files


def crop_images_only(folder_path, x_center, y_center, crop_width, crop_height):
    output_folder = os.path.join(os.path.expanduser("~"), "Desktop", "crop_results")
    os.makedirs(output_folder, exist_ok=True)
    img_exts = (".png", ".jpg", ".jpeg", ".bmp", ".tif", ".tiff")

    for filename in os.listdir(folder_path):
        if filename.lower().endswith(img_exts):
            try:
                image_path = os.path.join(folder_path, filename)
                img = Image.open(image_path).convert("RGB")
                width, height = img.size
                left = max(0, x_center - crop_width // 2)
                right = min(width, x_center + crop_width // 2)
                top = max(0, y_center - crop_height // 2)
                bottom = min(height, y_center + crop_height // 2)
                crop_img = img.crop((left, top, right, bottom))
                crop_img = crop_img.resize((crop_img.width * 2, crop_img.height * 2), Image.LANCZOS)
                bw = ImageOps.grayscale(crop_img)
                save_path = os.path.join(output_folder, f"crop_{filename}")
                bw.save(save_path)
            except:
                continue
    return output_folder


# ------------------------ Tab 1: ç½‘é¡µè¡¨æ ¼æŠ“å– ------------------------
with tab1:
    st.subheader("ç½‘é¡µè¡¨æ ¼æŠ“å–")
    urls_text = st.text_area("è¾“å…¥ç½‘é¡µURLåˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", height=120)
    group_cols = st.text_input("åˆ†ç»„åˆ—ï¼ˆé€—å·åˆ†éš”ï¼Œå¯é€‰ï¼‰")
    if st.button("æŠ“å–è¡¨æ ¼", key="scrape"):
        url_list = [u.strip() for u in urls_text.splitlines() if u.strip()]
        if url_list:
            output = scrape_table(url_list, group_cols)
            if output:
                st.download_button("ä¸‹è½½æŠ“å–è¡¨æ ¼", data=output.getvalue(), file_name="ç½‘é¡µæŠ“å–.xlsx")
            else:
                st.warning("æœªæŠ“å–åˆ°è¡¨æ ¼æ•°æ®")
        else:
            st.warning("è¯·å…ˆè¾“å…¥æœ‰æ•ˆURLåˆ—è¡¨")

# ------------------------ Tab 2: ç½‘é¡µå›¾ç‰‡ä¸‹è½½ ------------------------
with tab2:
    st.subheader("ç½‘é¡µå›¾ç‰‡ä¸‹è½½")
    urls_text2 = st.text_area("è¾“å…¥ç½‘é¡µURLåˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", height=120, key="img_urls")
    if st.button("ä¸‹è½½å›¾ç‰‡", key="img_download"):
        url_list = [u.strip() for u in urls_text2.splitlines() if u.strip()]
        if url_list:
            output_dir, files = download_images_from_urls(url_list)
            st.success(f"å®Œæˆï¼å…±ä¸‹è½½ {len(files)} å¼ å›¾ç‰‡ï¼Œä¿å­˜åˆ°: {output_dir}")
        else:
            st.warning("è¯·å…ˆè¾“å…¥æœ‰æ•ˆURLåˆ—è¡¨")

# ------------------------ Tab 3: å›¾ç‰‡è£å‰ª ------------------------
with tab3:
    st.subheader("å›¾ç‰‡è£å‰ªï¼ˆä»…è£å‰ªä¿å­˜ï¼‰")
    folder_path = st.text_input("å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰", key="img_folder")
    x_center = st.number_input("é¡µç ä¸­å¿ƒX", value=788, key="x_center")
    y_center = st.number_input("é¡µç ä¸­å¿ƒY", value=1955, key="y_center")
    crop_w = st.number_input("è£å‰ªå®½åº¦(px)", value=200, key="crop_w")
    crop_h = st.number_input("è£å‰ªé«˜åº¦(px)", value=50, key="crop_h")
    if st.button("è£å‰ªå›¾ç‰‡", key="crop_btn"):
        if folder_path and os.path.exists(folder_path):
            output_folder = crop_images_only(folder_path, x_center, y_center, crop_w, crop_h)
            st.success(f"å®Œæˆï¼è£å‰ªç»“æœå·²ä¿å­˜åˆ°æ¡Œé¢ï¼š{output_folder}")
        else:
            st.warning("è¯·æä¾›æœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„")

# ------------------------ Tab 4: é«˜æ ¡é€‰ç§‘è½¬æ¢ ------------------------
with tab4:
    st.subheader("é«˜æ ¡é€‰ç§‘è½¬æ¢")
    uploaded_file = st.file_uploader("ä¸Šä¼ Excelæ–‡ä»¶", type=["xlsx", "xls"], key="sel_excel")

    if uploaded_file:
        df = pd.read_excel(uploaded_file)
        st.write("åŸå§‹æ•°æ®é¢„è§ˆ", df.head())


        # å¤„ç†é€‰ç§‘è½¬æ¢
        def convert_selection_requirements(df):
            subject_mapping = {'ç‰©ç†': 'ç‰©', 'åŒ–å­¦': 'åŒ–', 'ç”Ÿç‰©': 'ç”Ÿ', 'å†å²': 'å†', 'åœ°ç†': 'åœ°', 'æ”¿æ²»': 'æ”¿',
                               'æ€æƒ³æ”¿æ²»': 'æ”¿'}
            df_new = df.copy()
            df_new['é¦–é€‰ç§‘ç›®'] = ''
            df_new['é€‰ç§‘è¦æ±‚ç±»å‹'] = ''
            df_new['æ¬¡é€‰'] = ''

            for idx, row in df.iterrows():
                text = str(row.get('é€‰ç§‘è¦æ±‚', '')).strip()
                cat = str(row.get('æ‹›ç”Ÿç§‘ç±»', '')).strip()
                subjects = [subject_mapping.get(s, s) for s in
                            re.findall(r'ç‰©ç†|åŒ–å­¦|ç”Ÿç‰©|å†å²|åœ°ç†|æ”¿æ²»|æ€æƒ³æ”¿æ²»', text)]
                first = ''
                for s_full, s_short in subject_mapping.items():
                    if f'é¦–é€‰{s_full}' in text:
                        first = s_short
                if not first:
                    if 'ç‰©ç†' in cat:
                        first = 'ç‰©'
                    elif 'å†å²' in cat:
                        first = 'å†'
                remaining = [s for s in subjects if s != first]
                second = ''.join(remaining)
                if 'ä¸é™' in text:
                    req_type = 'ä¸é™ç§‘ç›®ä¸“ä¸šç»„'
                elif len(remaining) >= 1:
                    req_type = 'å¤šé—¨é€‰è€ƒ'
                else:
                    req_type = 'å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ'
                df_new.at[idx, 'é¦–é€‰ç§‘ç›®'] = first
                df_new.at[idx, 'æ¬¡é€‰'] = second
                df_new.at[idx, 'é€‰ç§‘è¦æ±‚ç±»å‹'] = req_type
            return df_new


        if st.button("è½¬æ¢é€‰ç§‘", key="sel_btn"):
            df_result = convert_selection_requirements(df)
            st.write("è½¬æ¢ç»“æœé¢„è§ˆ", df_result.head())
            towrite = BytesIO()
            df_result.to_excel(towrite, index=False)
            st.download_button("ä¸‹è½½è½¬æ¢ç»“æœExcel", data=towrite.getvalue(), file_name="é€‰ç§‘è½¬æ¢ç»“æœ.xlsx")

# ------------------------ Tab 5: Excelæ—¥æœŸå¤„ç† ------------------------
with tab5:
    st.subheader("Excelæ—¥æœŸå¤„ç†")
    uploaded_file2 = st.file_uploader("ä¸Šä¼ Excelæ–‡ä»¶", type=["xlsx", "xls"], key="date_excel")

    if uploaded_file2:
        df2 = pd.read_excel(uploaded_file2)
        st.write("åŸå§‹æ•°æ®é¢„è§ˆ", df2.head())
        year = st.number_input("å¹´ä»½", value=2025, key="date_year")
        date_col = st.text_input("æ—¥æœŸåˆ—å", value="æ—¥æœŸ", key="date_col")


        def safe_parse_datetime(datetime_str, year):
            if pd.isna(datetime_str): return None
            datetime_str = str(datetime_str).strip()
            if not re.search(r'(^|\D)\d{4}(\D|$)', datetime_str):
                datetime_str = f"{year}å¹´{datetime_str}"
            patterns = [(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥(\d{1,2}):(\d{1,2})', '%Yå¹´%mæœˆ%dæ—¥%H:%M'),
                        (r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', '%Yå¹´%mæœˆ%dæ—¥'),
                        (r'(\d{4})-(\d{1,2})-(\d{1,2})', '%Y-%m-%d'),
                        (r'(\d{4})/(\d{1,2})/(\d{1,2})', '%Y/%m/%d')]
            for pattern, fmt in patterns:
                try:
                    dt = datetime.strptime(datetime_str, fmt)
                    return dt
                except:
                    continue
            return None


        def process_date_range(date_str):
            if pd.isna(date_str): return date_str, "", ""
            date_str = str(date_str).strip()
            if '-' in date_str:
                start_str, end_str = date_str.split('-', 1)
                start_dt = safe_parse_datetime(start_str, year)
                end_dt = safe_parse_datetime(end_str, year)
                if not start_dt or not end_dt: return date_str, "æ ¼å¼é”™è¯¯", "æ ¼å¼é”™è¯¯"
                if ':' not in start_str: start_dt = start_dt.replace(hour=0, minute=0, second=0)
                if ':' not in end_str: end_dt = end_dt.replace(hour=23, minute=59, second=59)
                if end_dt < start_dt: end_dt = end_dt.replace(year=year + 1)
                return date_str, start_dt.strftime('%Y-%m-%d %H:%M:%S'), end_dt.strftime('%Y-%m-%d %H:%M:%S')
            else:
                dt = safe_parse_datetime(date_str, year)
                if not dt: return date_str, "æ ¼å¼é”™è¯¯", "æ ¼å¼é”™è¯¯"
                start_dt = dt.replace(hour=0, minute=0, second=0) if ':' not in date_str else dt
                end_dt = dt.replace(hour=23, minute=59, second=59) if ':' not in date_str else dt
                return date_str, start_dt.strftime('%Y-%m-%d %H:%M:%S'), end_dt.strftime('%Y-%m-%d %H:%M:%S')


        if st.button("å¤„ç†æ—¥æœŸ", key="date_btn"):
            start_times = []
            end_times = []
            originals = []
            for d in df2[date_col]:
                orig, start, end = process_date_range(d)
                originals.append(orig)
                start_times.append(start)
                end_times.append(end)
            df2_result = df2.copy()
            df2_result.insert(df2_result.columns.get_loc(date_col) + 1, 'å¼€å§‹æ—¶é—´', start_times)
            df2_result.insert(df2_result.columns.get_loc(date_col) + 2, 'ç»“æŸæ—¶é—´', end_times)
            st.write("å¤„ç†ç»“æœé¢„è§ˆ", df2_result.head())
            towrite2 = BytesIO()
            df2_result.to_excel(towrite2, index=False)
            st.download_button("ä¸‹è½½æ—¥æœŸå¤„ç†ç»“æœExcel", data=towrite2.getvalue(), file_name="æ—¥æœŸå¤„ç†ç»“æœ.xlsx")
